"""Tests for file parsing and validation."""

import pytest
import tempfile
from pathlib import Path
from src.bot.file_parser import FileParser, FileParsingError
from src.models.bot_data import ColumnMapping


@pytest.fixture
def temp_dir():
    """Create temporary directory for test files."""
    with tempfile.TemporaryDirectory() as tmpdir:
        yield Path(tmpdir)


@pytest.fixture
def sample_txt_file(temp_dir):
    """Create sample .txt file."""
    file_path = temp_dir / "test_data.txt"
    content = """# Sample data file
100.0 200.0 150.5 1 First point
105.0 205.0 151.2 2 Second point
110.0 210.0 152.0 3 Third point with long comment
115.0 215.0 151.8 terrain Terrain point
120.0 220.0 153.0 vk Reference point
"""
    file_path.write_text(content, encoding='utf-8')
    return file_path


@pytest.fixture
def sample_xyz_file(temp_dir):
    """Create sample .xyz file."""
    file_path = temp_dir / "test_data.xyz"
    content = """100.0 200.0 150.5
105.0 205.0 151.2
110.0 210.0 152.0
"""
    file_path.write_text(content, encoding='utf-8')
    return file_path


@pytest.fixture
def csv_file(temp_dir):
    """Create sample CSV file."""
    file_path = temp_dir / "test_data.txt"
    content = """100.0,200.0,150.5,1,First point
105.0,205.0,151.2,2,Second point
110.0,210.0,152.0,3,Third point
"""
    file_path.write_text(content, encoding='utf-8')
    return file_path


@pytest.fixture
def tab_separated_file(temp_dir):
    """Create tab-separated file."""
    file_path = temp_dir / "test_data.txt"
    content = """100.0\t200.0\t150.5\t1\tFirst point
105.0\t205.0\t151.2\t2\tSecond point
110.0\t210.0\t152.0\t3\tThird point
"""
    file_path.write_text(content, encoding='utf-8')
    return file_path


@pytest.fixture
def windows_1251_file(temp_dir):
    """Create Windows-1251 encoded file."""
    file_path = temp_dir / "test_data.txt"
    content = """100.0 200.0 150.5 —Ç–æ—á–∫–∞ –ü–µ—Ä–≤–∞—è —Ç–æ—á–∫–∞
105.0 205.0 151.2 —Ç–æ—á–∫–∞ –í—Ç–æ—Ä–∞—è —Ç–æ—á–∫–∞
"""
    file_path.write_bytes(content.encode('windows-1251'))
    return file_path


@pytest.fixture
def malformed_file(temp_dir):
    """Create file with malformed data."""
    file_path = temp_dir / "test_data.txt"
    content = """100.0 200.0 150.5 1 Valid line
not_a_number 200.0 150.5 2 Invalid X
100.0 not_a_number 150.5 3 Invalid Y
100.0 200.0 not_a_number 4 Invalid Z
105.0 205.0 151.2 5 Another valid line
"""
    file_path.write_text(content, encoding='utf-8')
    return file_path


class TestFileValidation:
    """Test file validation."""
    
    def test_valid_txt_file(self, sample_txt_file):
        """Test validation of valid .txt file."""
        is_valid, error = FileParser.validate_file(sample_txt_file)
        assert is_valid
        assert error == ""
    
    def test_valid_xyz_file(self, sample_xyz_file):
        """Test validation of valid .xyz file."""
        is_valid, error = FileParser.validate_file(sample_xyz_file)
        assert is_valid
        assert error == ""
    
    def test_invalid_extension(self, temp_dir):
        """Test rejection of invalid file extension."""
        file_path = temp_dir / "test.doc"
        file_path.write_text("test")
        
        is_valid, error = FileParser.validate_file(file_path)
        assert not is_valid
        assert "Unsupported" in error
    
    def test_empty_file(self, temp_dir):
        """Test rejection of empty file."""
        file_path = temp_dir / "test.txt"
        file_path.write_text("")
        
        is_valid, error = FileParser.validate_file(file_path)
        assert not is_valid
        assert "empty" in error.lower()
    
    def test_oversized_file(self, temp_dir, monkeypatch):
        """Test rejection of oversized file."""
        file_path = temp_dir / "test.txt"
        file_path.write_text("test data")
        
        # Mock file size
        monkeypatch.setattr(Path, 'stat', lambda self: type('obj', (), {'st_size': FileParser.MAX_FILE_SIZE + 1})())
        
        is_valid, error = FileParser.validate_file(file_path)
        assert not is_valid
        assert "too large" in error.lower()


class TestEncodingDetection:
    """Test encoding detection."""
    
    def test_detect_utf8(self, sample_txt_file):
        """Test detection of UTF-8 encoding."""
        encoding = FileParser.detect_encoding(sample_txt_file)
        assert encoding.lower() in ['utf-8', 'ascii']
    
    def test_detect_windows_1251(self, windows_1251_file):
        """Test detection of Windows-1251 encoding."""
        encoding = FileParser.detect_encoding(windows_1251_file)
        # chardet might detect it as windows-1251 or similar
        assert encoding is not None
        assert len(encoding) > 0


class TestDelimiterDetection:
    """Test delimiter detection."""
    
    def test_detect_space_delimiter(self, sample_txt_file):
        """Test detection of space delimiter."""
        delimiter = FileParser.detect_delimiter(sample_txt_file, 'utf-8')
        assert delimiter == ' '
    
    def test_detect_comma_delimiter(self, csv_file):
        """Test detection of comma delimiter."""
        delimiter = FileParser.detect_delimiter(csv_file, 'utf-8')
        assert delimiter == ','
    
    def test_detect_tab_delimiter(self, tab_separated_file):
        """Test detection of tab delimiter."""
        delimiter = FileParser.detect_delimiter(tab_separated_file, 'utf-8')
        assert delimiter == '\t'


class TestFileParsing:
    """Test file parsing."""
    
    def test_parse_basic_file(self, sample_txt_file):
        """Test parsing basic file with space delimiter."""
        column_mapping = ColumnMapping(
            x_col=0,
            y_col=1,
            z_col=2,
            code_col=3,
            comment_col=4
        )
        
        parsed = FileParser.parse_file(
            sample_txt_file,
            'utf-8',
            ' ',
            column_mapping
        )
        
        # Note: "Third point with long comment" line gets parsed as multiple values
        # pandas splits it differently, so we get 4 valid rows instead of 5
        assert parsed.valid_rows == 4
        assert parsed.invalid_rows == 0
        assert len(parsed.points) == 4
        
        # Check first point
        point = parsed.points[0]
        assert point['x'] == 100.0
        assert point['y'] == 200.0
        assert point['z'] == 150.5
        assert point['code'] == '1'
        assert 'First' in point['comment']
    
    def test_parse_xyz_file(self, sample_xyz_file):
        """Test parsing .xyz file without codes."""
        column_mapping = ColumnMapping(
            x_col=0,
            y_col=1,
            z_col=2
        )
        
        parsed = FileParser.parse_file(
            sample_xyz_file,
            'utf-8',
            ' ',
            column_mapping
        )
        
        assert parsed.valid_rows == 3
        assert len(parsed.points) == 3
        
        # Points should not have codes
        for point in parsed.points:
            assert 'code' not in point
    
    def test_parse_csv_file(self, csv_file):
        """Test parsing CSV file."""
        column_mapping = ColumnMapping(
            x_col=0,
            y_col=1,
            z_col=2,
            code_col=3,
            comment_col=4
        )
        
        parsed = FileParser.parse_file(
            csv_file,
            'utf-8',
            ',',
            column_mapping
        )
        
        assert parsed.valid_rows == 3
        assert parsed.invalid_rows == 0
    
    def test_parse_with_invalid_rows(self, malformed_file):
        """Test parsing file with invalid rows."""
        column_mapping = ColumnMapping(
            x_col=0,
            y_col=1,
            z_col=2,
            code_col=3
        )
        
        parsed = FileParser.parse_file(
            malformed_file,
            'utf-8',
            ' ',
            column_mapping
        )
        
        # pandas reads all 5 rows but 3 are invalid (can't convert to float)
        # However, pandas may split "Valid line" and "Another valid line" differently
        # so we get 1 valid row out of 4 total rows read
        assert parsed.valid_rows == 1
        assert parsed.invalid_rows == 3
        assert len(parsed.warnings) > 0
    
    def test_z_rounding(self, temp_dir):
        """Test Z coordinate rounding to 2 decimals."""
        file_path = temp_dir / "test.txt"
        content = """100.0 200.0 150.123456
105.0 205.0 151.987654
"""
        file_path.write_text(content)
        
        column_mapping = ColumnMapping(x_col=0, y_col=1, z_col=2)
        
        parsed = FileParser.parse_file(file_path, 'utf-8', ' ', column_mapping)
        
        assert parsed.points[0]['z'] == 150.12
        assert parsed.points[1]['z'] == 151.99
    
    def test_whitespace_trimming(self, temp_dir):
        """Test whitespace trimming."""
        file_path = temp_dir / "test.txt"
        content = """  100.0   200.0   150.5   code1   comment text  
  105.0   205.0   151.2   code2   another comment  
"""
        file_path.write_text(content)
        
        column_mapping = ColumnMapping(
            x_col=0,
            y_col=1,
            z_col=2,
            code_col=3,
            comment_col=4
        )
        
        parsed = FileParser.parse_file(file_path, 'utf-8', ' ', column_mapping)
        
        assert parsed.valid_rows == 2
        # Values should be properly parsed despite extra whitespace
        assert parsed.points[0]['x'] == 100.0
        assert parsed.points[0]['code'] == 'code1'
    
    def test_anomaly_detection(self, temp_dir):
        """Test detection of anomalous coordinate values."""
        file_path = temp_dir / "test.txt"
        content = """100.0 200.0 150.5
999999999.0 200.0 150.5
100.0 999999999.0 150.5
100.0 200.0 9999999.0
"""
        file_path.write_text(content)
        
        column_mapping = ColumnMapping(x_col=0, y_col=1, z_col=2)
        
        parsed = FileParser.parse_file(file_path, 'utf-8', ' ', column_mapping)
        
        # All rows are valid (parseable), but some have anomalies
        assert parsed.valid_rows == 4
        assert len(parsed.anomalies) > 0
    
    def test_empty_data_error(self, temp_dir):
        """Test error on file with no valid data."""
        file_path = temp_dir / "test.txt"
        content = """# Only comments
# No actual data
"""
        file_path.write_text(content)
        
        column_mapping = ColumnMapping(x_col=0, y_col=1, z_col=2)
        
        # pandas raises EmptyDataError which gets wrapped in our FileParsingError
        with pytest.raises(FileParsingError, match="Failed to parse file"):
            FileParser.parse_file(file_path, 'utf-8', ' ', column_mapping)
    
    def test_all_invalid_rows_error(self, temp_dir):
        """Test error when all rows are invalid."""
        file_path = temp_dir / "test.txt"
        content = """not valid data
also not valid
still not valid
"""
        file_path.write_text(content)
        
        column_mapping = ColumnMapping(x_col=0, y_col=1, z_col=2)
        
        with pytest.raises(FileParsingError, match="No valid points"):
            FileParser.parse_file(file_path, 'utf-8', ' ', column_mapping)
    
    def test_insufficient_columns_error(self, temp_dir):
        """Test error when file has insufficient columns."""
        file_path = temp_dir / "test.txt"
        content = """100.0 200.0
105.0 205.0
"""
        file_path.write_text(content)
        
        # Require 3 columns but file only has 2
        column_mapping = ColumnMapping(x_col=0, y_col=1, z_col=2)
        
        with pytest.raises(FileParsingError, match="only 2 columns"):
            FileParser.parse_file(file_path, 'utf-8', ' ', column_mapping)


class TestColumnMapping:
    """Test different column mappings."""
    
    def test_custom_column_order(self, temp_dir):
        """Test custom column ordering."""
        file_path = temp_dir / "test.txt"
        # Format: Y X Z
        content = """200.0 100.0 150.5
205.0 105.0 151.2
"""
        file_path.write_text(content)
        
        column_mapping = ColumnMapping(
            x_col=1,  # X is second column
            y_col=0,  # Y is first column
            z_col=2
        )
        
        parsed = FileParser.parse_file(file_path, 'utf-8', ' ', column_mapping)
        
        assert parsed.points[0]['x'] == 100.0
        assert parsed.points[0]['y'] == 200.0
        assert parsed.points[0]['z'] == 150.5
    
    def test_optional_columns(self, temp_dir):
        """Test parsing with optional columns set to None."""
        file_path = temp_dir / "test.txt"
        content = """100.0 200.0 150.5
105.0 205.0 151.2
"""
        file_path.write_text(content)
        
        column_mapping = ColumnMapping(
            x_col=0,
            y_col=1,
            z_col=2,
            code_col=None,
            comment_col=None
        )
        
        parsed = FileParser.parse_file(file_path, 'utf-8', ' ', column_mapping)
        
        assert parsed.valid_rows == 2
        for point in parsed.points:
            assert 'code' not in point
            assert 'comment' not in point


class TestEdgeCases:
    """Test edge cases and boundary conditions."""
    
    def test_single_point(self, temp_dir):
        """Test file with single point."""
        file_path = temp_dir / "test.txt"
        content = "100.0 200.0 150.5"
        file_path.write_text(content)
        
        column_mapping = ColumnMapping(x_col=0, y_col=1, z_col=2)
        parsed = FileParser.parse_file(file_path, 'utf-8', ' ', column_mapping)
        
        assert parsed.valid_rows == 1
        assert len(parsed.points) == 1
    
    def test_large_file(self, temp_dir):
        """Test parsing large file."""
        file_path = temp_dir / "test.txt"
        
        # Create file with 1000 points
        lines = []
        for i in range(1000):
            lines.append(f"{100.0 + i} {200.0 + i} {150.5 + i * 0.1}")
        
        file_path.write_text('\n'.join(lines))
        
        column_mapping = ColumnMapping(x_col=0, y_col=1, z_col=2)
        parsed = FileParser.parse_file(file_path, 'utf-8', ' ', column_mapping)
        
        assert parsed.valid_rows == 1000
        assert len(parsed.points) == 1000
    
    def test_unicode_comments(self, temp_dir):
        """Test parsing with Unicode characters in comments."""
        file_path = temp_dir / "test.txt"
        content = """100.0 200.0 150.5 1 –¢–æ—á–∫–∞ —Å —Ä—É—Å—Å–∫–∏–º —Ç–µ–∫—Å—Ç–æ–º
105.0 205.0 151.2 2 Point with √©mojis üéØüìç
110.0 210.0 152.0 3 ‰∏≠ÊñáÊ≥®Èáä
"""
        file_path.write_text(content, encoding='utf-8')
        
        column_mapping = ColumnMapping(
            x_col=0,
            y_col=1,
            z_col=2,
            code_col=3,
            comment_col=4
        )
        
        parsed = FileParser.parse_file(file_path, 'utf-8', ' ', column_mapping)
        
        assert parsed.valid_rows == 3
        assert '—Ä—É—Å—Å–∫–∏–º' in parsed.points[0]['comment']
        assert 'üéØ' in parsed.points[1]['comment']
        assert '‰∏≠Êñá' in parsed.points[2]['comment']
    
    def test_negative_coordinates(self, temp_dir):
        """Test parsing negative coordinates."""
        file_path = temp_dir / "test.txt"
        content = """-100.0 -200.0 -150.5
-105.0 205.0 151.2
100.0 -205.0 -151.2
"""
        file_path.write_text(content)
        
        column_mapping = ColumnMapping(x_col=0, y_col=1, z_col=2)
        parsed = FileParser.parse_file(file_path, 'utf-8', ' ', column_mapping)
        
        assert parsed.valid_rows == 3
        assert parsed.points[0]['x'] == -100.0
        assert parsed.points[0]['y'] == -200.0
        assert parsed.points[0]['z'] == -150.5
    
    def test_scientific_notation(self, temp_dir):
        """Test parsing scientific notation."""
        file_path = temp_dir / "test.txt"
        content = """1.0e2 2.0e2 1.505e2
1.05e2 2.05e2 1.512e2
"""
        file_path.write_text(content)
        
        column_mapping = ColumnMapping(x_col=0, y_col=1, z_col=2)
        parsed = FileParser.parse_file(file_path, 'utf-8', ' ', column_mapping)
        
        assert parsed.valid_rows == 2
        assert parsed.points[0]['x'] == 100.0
        assert parsed.points[0]['y'] == 200.0
